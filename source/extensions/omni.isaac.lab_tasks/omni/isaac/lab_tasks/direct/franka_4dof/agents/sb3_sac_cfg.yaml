seed: 42
algorithm: 'sac'
name: 'Franka_4dof'
# epoch * n_steps * nenvs: 500×512*8*8
n_timesteps: !!float 5e5 # 500000 
policy: 'MlpPolicy'
# n_steps: 64
# mini batch size: num_envs * nsteps / nminibatches 2048×512÷2048
batch_size: 128
buffer_size: 5000000 #5e5                         ### NEED TO CHANGE TO 1e6 IF POOR TRAINING
ent_coef: 'auto'
gamma: 0.99
tau: 0.005
train_freq: [5, "step"]
# train_freq: 64
gradient_steps: -1
# gradient_steps: 64
learning_starts: 1000 #500
use_sde_at_warmup: True
use_sde: True
sde_sample_freq: 64
learning_rate: !!float 3e-4
policy_kwargs: "dict(
                  log_std_init=-2, 
                  net_arch=[256, 256]
                )"

# # Uses VecNormalize class to normalize obs
normalize_input: True
# # Uses VecNormalize class to normalize rew
# normalize_value: True
# clip_obs: 5